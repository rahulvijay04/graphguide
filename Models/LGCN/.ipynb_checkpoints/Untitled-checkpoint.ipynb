{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b762768-6e00-47ff-adb3-c18ec10fccad",
   "metadata": {},
   "source": [
    "### LightGCN implementation for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd61ab0e-de1f-4170-8b51-bc1392ab52b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10647a9b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!python -m pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.2%2Bcu121.html\n",
    "#!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
    "#!pip install torch-geometric\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004669e7-1cd5-4e7c-9f11-be80a40753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "class BipartiteData(Data):\n",
    "    def __init__(self, edge_index_u2a=None, edge_index_a2u=None, num_artists=None, num_users=None):\n",
    "        super().__init__()\n",
    "        self.edge_index_u2a = edge_index_u2a\n",
    "        self.edge_index_a2u = edge_index_a2u\n",
    "        self.num_users = num_users\n",
    "        self.num_artists = num_artists\n",
    "\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        # Returns the incremental count to cumulatively increase the value\n",
    "        # of the next attribute of :obj:`key` when creating batches.\n",
    "        if key == 'edge_index_u2a':\n",
    "            return torch.tensor([[self.num_users], [self.num_artists]])\n",
    "        elif key == 'edge_index_a2u':\n",
    "            return torch.tensor([[self.num_artists], [self.num_users]])\n",
    "        else:\n",
    "            return super(BipartiteData, self).__inc__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb83ff2e-b4df-428d-ba64-a3bee1df45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.get_pyg_data import load_bipartitedata\n",
    "import torch.nn as nn\n",
    "#import torch_scatter\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774945ce-8293-4a66-9e9f-8bee2b6c1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LightGCN, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        return self.propagate(edge_index=edge_index, x=(x[0], x[1]), size=size)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        return torch_scatter.scatter(src=inputs, index=index, dim=0, dim_size=dim_size, reduce='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d3e880-b1c0-4f3f-882e-221b0da4ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNStack(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(LightGCNStack, self).__init__()\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.num_layers = args.num_layers\n",
    "        self.dataset = None\n",
    "        self.embeddings_users = None\n",
    "        self.embeddings_artists = None\n",
    "        self.lambda_reg = args.lambda_reg\n",
    "\n",
    "        conv_model = LightGCN\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model())\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model())\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embeddings.reset_parameters()\n",
    "\n",
    "    def init_data(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.embeddings_users = torch.nn.Embedding(num_embeddings=dataset.num_users, embedding_dim=self.latent_dim).to('cuda')\n",
    "        self.embeddings_artists = torch.nn.Embedding(num_embeddings=dataset.num_artists, embedding_dim=self.latent_dim).to('cuda')\n",
    "\n",
    "    def forward(self):\n",
    "        x_users, x_artists = self.embeddings_users.weight, self.embeddings_artists.weight\n",
    "                                                \n",
    "        final_embeddings_users = torch.zeros(size=x_users.size(), device='cuda')\n",
    "        final_embeddings_artists = torch.zeros(size=x_artists.size(), device='cuda')\n",
    "        final_embeddings_users = final_embeddings_users + x_users/(self.num_layers + 1)\n",
    "        final_embeddings_artists = final_embeddings_artists + x_artists/(self.num_layers+1)\n",
    "        for i in range(self.num_layers):\n",
    "            x_users = self.convs[i]((x_artists, x_users), self.dataset.edge_index_a2u, size=(self.dataset.num_artists, self.dataset.num_users))\n",
    "            x_artists = self.convs[i]((x_users, x_artists), self.dataset.edge_index_u2a, size=(self.dataset.num_users, self.dataset.num_artists))\n",
    "            final_embeddings_users = final_embeddings_users + x_users/(self.num_layers+1)\n",
    "            final_embeddings_artists = final_embeddings_artists + x_artists/(self.num_layers + 1)\n",
    "\n",
    "        return final_embeddings_users, final_embeddings_artists\n",
    "\n",
    "    \n",
    "    def decode(self, z1, z2, pos_edge_index, neg_edge_index):  \n",
    "        ''' \n",
    "        Getting recommendation scores for the edges in pos_edge_index and neg_edge_index.\n",
    "        z1 and z2 are torch.nn.Embeddings objects. If edge index is of form \n",
    "        (user, artist) then z1 will be user embedding matrix and z2 will be \n",
    "        artist embedding matrix, else the parameters are flipped. \n",
    "        '''\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)  # concatenate pos and neg edges\n",
    "        logits = (z1[edge_index[0]] * z2[edge_index[1]]).sum(dim=-1)  # dot product\n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z_users, z_artists):\n",
    "        '''\n",
    "        Get ranking score matrix for all combinations of users and artists\n",
    "        '''\n",
    "        prob_adj = z_users @ z_artists.t() # dot product between all combinations\n",
    "        return prob_adj\n",
    "\n",
    "    def BPRLoss(self, prob_adj, real_adj, edge_index):\n",
    "        '''\n",
    "        Custom written BPR Loss function. It uses full-batch calculation, so it \n",
    "        requires a lot of resources and does not scale for very large graphs. \n",
    "        For our dataset, it will do.\n",
    "\n",
    "        prob_adj: NxM ranking score matrix for all users and artists\n",
    "        real_adj: Real adjacency matrix of type scipy.sparse.coo_matrix\n",
    "        edge_index: index of graph edges\n",
    "        '''\n",
    "        loss = 0\n",
    "        pos_scores = prob_adj[edge_index.cpu().numpy()]\n",
    "        for pos_score, node_index in zip(pos_scores, edge_index[0]):\n",
    "            neg_scores = prob_adj[node_index, real_adj[node_index] == 0]\n",
    "            loss = loss - torch.sum(torch.log(torch.sigmoid(pos_score.repeat(neg_scores.size()[0]) - neg_scores))) / \\\n",
    "                   neg_scores.size()[0]\n",
    "\n",
    "        loss += self.lambda_reg*(torch.pow(torch.norm(self.embeddings_users.weight, dim=None), 2) +\n",
    "                                 torch.pow(torch.norm(self.embeddings_artists.weight), 2))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def topN(self, user_id, n):\n",
    "        '''\n",
    "        Get indices of top N recommendations for user with ID user_id based on \n",
    "        ranking scores.\n",
    "        '''\n",
    "        z_users, z_artists = self.forward()\n",
    "        scores = torch.squeeze(z_users[user_id] @ z_artists.t())\n",
    "        return torch.topk(scores, k=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889d4646-9e81-4182-989f-5c99e368d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "def to_scipy_sparse_matrix(edge_index, num_nodes):\n",
    "    row, col = edge_index.cpu()\n",
    "    edge_attr = torch.ones(row.size(0))\n",
    "    out = scipy.sparse.coo_matrix(\n",
    "        (edge_attr.numpy(), (row.numpy(), col.numpy())), (num_nodes[0], num_nodes[1]))\n",
    "    return out\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data.neg_edge_index_u2a = negative_sampling(\n",
    "        edge_index=data.edge_index_u2a,  # positive edges\n",
    "        num_nodes=(data.num_users, data.num_artists),  # number of nodes\n",
    "        num_neg_samples=data.edge_index_u2a.size(1),\n",
    "        method='sparse').to('cuda')  # number of neg_sample equal to number of pos_edges\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z_users, z_artists = model.forward()  # encode\n",
    "    loss = model.BPRLoss(model.decode_all(z_users, z_artists),\n",
    "                         to_scipy_sparse_matrix(data.edge_index_u2a, num_nodes=(data.num_users, data.num_artists)).toarray(),\n",
    "                         data.edge_index_u2a)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4daeff35-49e9-46f7-8c0e-eea0c51eb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        d = dict(*args, **kwargs)\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb588b8-5840-4b13-89e7-adb131638103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Wrapper for evaluation\n",
    "class LightGCN_recommender:\n",
    "    def __init__(self, args):\n",
    "        self.args = objectview(args)\n",
    "        self.model = LightGCNStack(args=self.args).to('cuda')\n",
    "        self.a_rev_dict = None\n",
    "        self.u_rev_dict = None\n",
    "        self.a_dict = None\n",
    "        self.u_dict = None\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        # Default rankings when userID is not in training set\n",
    "        self.default_recommendation = data[\"item_id\"].value_counts().index.tolist()\n",
    "\n",
    "        # LightGCN\n",
    "        data, self.u_rev_dict, self.a_rev_dict, self.u_dict, self.a_dict = load_bipartitedata(data)\n",
    "        data = data.to(\"cuda\")\n",
    "        self.model.init_data(data)\n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=0.001)\n",
    "\n",
    "        best_val_perf = test_perf = 0\n",
    "\n",
    "        for epoch in range(1, self.args.epochs+1):\n",
    "            start = time.time()\n",
    "            train_loss = train(self.model, data, self.optimizer)\n",
    "            log = 'Epoch: {:03d}, Loss: {:.4f}, Elapsed time: {:.2f}'\n",
    "            print(log.format(epoch, train_loss, time.time()-start))\n",
    "\n",
    "    def recommend(self, user_id, n):\n",
    "        try:\n",
    "            recommendations = self.model.topN(self.u_dict[str(user_id)], n=n)\n",
    "        except KeyError:\n",
    "\n",
    "            recommendations = self.default_recommendation\n",
    "        else:\n",
    "            recommendations = recommendations.indices.cpu().tolist()\n",
    "            recommendations = list(map(lambda x: self.a_rev_dict[x], recommendations))\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86942be0-2a86-4e53-b113-79649b0c5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "args = {'model_type': 'LightGCN', 'num_layers': 3, 'latent_dim': 32,\n",
    "         'dropout': 0, 'epochs': 100, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3,\n",
    "         'lr': 0.1, 'lambda_reg': 1e-4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e9268-1ce7-43c7-a045-3374713f53fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
